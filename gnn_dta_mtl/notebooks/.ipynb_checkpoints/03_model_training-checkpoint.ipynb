{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1b937-1966-4407-aa88-4acb86c879a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Training Example Notebook\n",
    "\"\"\"\n",
    "\n",
    "# Cell 1: Setup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from gnn_dta_mtl import MTL_DTAModel, MTLTrainer, CrossValidator\n",
    "from gnn_dta_mtl.datasets import build_mtl_dataset_optimized\n",
    "from gnn_dta_mtl.features import StructureChunkLoader\n",
    "from gnn_dta_mtl.utils import prepare_mtl_experiment\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Cell 2: Load Data\n",
    "# Load your prepared dataframe\n",
    "df = pd.read_parquet(\"../data/standardized/standardized_input.parquet\")\n",
    "\n",
    "# Define tasks\n",
    "task_cols = ['pKi', 'pEC50', 'pKd', 'pIC50']\n",
    "\n",
    "# Calculate task ranges\n",
    "task_ranges = prepare_mtl_experiment(df, task_cols)\n",
    "\n",
    "# Cell 3: Load Structure Chunks\n",
    "# Initialize chunk loader for efficient structure loading\n",
    "chunk_loader = StructureChunkLoader(\n",
    "    chunk_dir=\"../data/structure_chunks/\",\n",
    "    cache_size=2\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(chunk_loader.get_available_pdb_ids())} protein structures\")\n",
    "\n",
    "# Cell 4: Prepare Dataset\n",
    "# Filter dataframe to available structures\n",
    "available_pdb_ids = chunk_loader.get_available_pdb_ids()\n",
    "df['protein_id'] = df['standardized_protein_pdb'].apply(\n",
    "    lambda p: os.path.splitext(os.path.basename(p))[0]\n",
    ")\n",
    "df_clean = df[df['protein_id'].isin(available_pdb_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset size: {len(df_clean)}\")\n",
    "\n",
    "# Cell 5: Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/valid/test\n",
    "train_df, test_df = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.125, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Valid: {len(valid_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# Cell 6: Create Datasets\n",
    "from gnn_dta_mtl.datasets import build_mtl_dataset_optimized\n",
    "import torch_geometric\n",
    "\n",
    "# Build datasets\n",
    "train_dataset = build_mtl_dataset_optimized(train_df, chunk_loader, task_cols)\n",
    "valid_dataset = build_mtl_dataset_optimized(valid_df, chunk_loader, task_cols)\n",
    "test_dataset = build_mtl_dataset_optimized(test_df, chunk_loader, task_cols)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = torch_geometric.loader.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "valid_loader = torch_geometric.loader.DataLoader(\n",
    "    valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "test_loader = torch_geometric.loader.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "# Cell 7: Initialize Model\n",
    "model = MTL_DTAModel(\n",
    "    task_names=task_cols,\n",
    "    prot_emb_dim=1280,\n",
    "    prot_gcn_dims=[128, 256, 256],\n",
    "    prot_fc_dims=[1024, 128],\n",
    "    drug_node_in_dim=[66, 1],\n",
    "    drug_node_h_dims=[128, 64],\n",
    "    drug_fc_dims=[1024, 128],\n",
    "    mlp_dims=[1024, 512],\n",
    "    mlp_dropout=0.25\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Cell 8: Train Model\n",
    "trainer = MTLTrainer(\n",
    "    model=model,\n",
    "    task_cols=task_cols,\n",
    "    task_ranges=task_ranges,\n",
    "    device=device,\n",
    "    learning_rate=0.0005,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    n_epochs=100,\n",
    "    patience=20,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Cell 9: Evaluate on Test Set\n",
    "test_results = trainer.predict(test_loader)\n",
    "\n",
    "# Print results\n",
    "from gnn_dta_mtl.evaluation import calculate_metrics\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for task, data in test_results.items():\n",
    "    metrics = calculate_metrics(data['targets'], data['predictions'])\n",
    "    print(f\"{task}:\")\n",
    "    print(f\"  RMSE: {metrics['rmse']:.3f}\")\n",
    "    print(f\"  RÂ²: {metrics['r2']:.3f}\")\n",
    "    print(f\"  MAE: {metrics['mae']:.3f}\")\n",
    "    print(f\"  Samples: {len(data['targets'])}\")\n",
    "\n",
    "# Cell 10: Visualize Results\n",
    "from gnn_dta_mtl.evaluation import plot_predictions\n",
    "\n",
    "# Plot predictions\n",
    "fig = plot_predictions(test_results, task_cols)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 11: Save Model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'task_cols': task_cols,\n",
    "    'task_ranges': task_ranges,\n",
    "    'model_config': {\n",
    "        'prot_emb_dim': 1280,\n",
    "        'prot_gcn_dims': [128, 256, 256],\n",
    "        'prot_fc_dims': [1024, 128],\n",
    "        'drug_node_in_dim': [66, 1],\n",
    "        'drug_node_h_dims': [128, 64],\n",
    "        'drug_fc_dims': [1024, 128],\n",
    "        'mlp_dims': [1024, 512],\n",
    "        'mlp_dropout': 0.25\n",
    "    }\n",
    "}, '../models/trained_model.pt')\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-chemprop_MTL-chemprop_mtl",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "chemprop_MTL",
   "language": "python",
   "name": "conda-env-chemprop_MTL-chemprop_mtl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
