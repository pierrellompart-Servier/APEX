{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d61477-aeb1-4d34-a2b5-b521c5cbfeb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_scatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Import MTL-GNN-DTA modules\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, AffinityPredictor\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     standardize_protein,\n\u001b[1;32m     31\u001b[0m     standardize_ligand,\n\u001b[1;32m     32\u001b[0m     validate_structures\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DrugFeaturizer, ProteinFeaturizer\n",
      "File \u001b[0;32m~/repo_perso/APEX/examples/notebooks/../../mtl_gnn_dta/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Core imports\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AffinityPredictor\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelTrainer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Model imports\u001b[39;00m\n",
      "File \u001b[0;32m~/repo_perso/APEX/examples/notebooks/../../mtl_gnn_dta/core/predictor.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdta_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MTL_DTAModel\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotein_features\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProteinFeaturizer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdrug_features\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DrugFeaturizer\n",
      "File \u001b[0;32m~/repo_perso/APEX/examples/notebooks/../../mtl_gnn_dta/models/dta_model.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotein_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProteinGCN\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdrug_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DrugGCN\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMTL_DTAModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Multi-Task Learning Model for Drug-Target Affinity Prediction\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Combines protein and drug graph representations for multi-task prediction\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/repo_perso/APEX/examples/notebooks/../../mtl_gnn_dta/models/drug_encoder.py:259\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GINConv, global_mean_pool, global_max_pool, global_add_pool\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmtl_gnn_dta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgvp_layers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GVP, LayerNorm, GVPConvLayer\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDrugGVPModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Drug encoder using Geometric Vector Perceptrons\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/repo_perso/APEX/examples/notebooks/../../mtl_gnn_dta/models/gvp_layers.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_scatter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scatter_add\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuple, Optional, List\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_scatter'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example Notebook 1: Data Preparation for MTL-GNN-DTA\n",
    "This notebook demonstrates how to prepare and process data for training\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "# # Data Preparation for MTL-GNN-DTA\n",
    "# \n",
    "# This notebook demonstrates:\n",
    "# 1. Loading and processing raw affinity data\n",
    "# 2. Standardizing molecular structures\n",
    "# 3. Computing molecular properties\n",
    "# 4. Preparing data for model training\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup and Imports\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Import MTL-GNN-DTA modules\n",
    "from mtl_gnn_dta import Config, AffinityPredictor\n",
    "from mtl_gnn_dta.preprocessing import (\n",
    "    standardize_protein,\n",
    "    standardize_ligand,\n",
    "    validate_structures\n",
    ")\n",
    "from mtl_gnn_dta.features import DrugFeaturizer, ProteinFeaturizer\n",
    "from mtl_gnn_dta.utils import setup_logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup logging\n",
    "setup_logging()\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"MTL-GNN-DTA Data Preparation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Load Configuration\n",
    "\n",
    "# %%\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "# Or load from file\n",
    "# config = Config('../../experiments/configs/default_config.yaml')\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Data directory: {config.data.processed_dir}\")\n",
    "print(f\"  Task names: {config.model.task_names}\")\n",
    "print(f\"  Batch size: {config.data.batch_size}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Load Raw Data\n",
    "\n",
    "# %%\n",
    "# Example: Load a sample dataset\n",
    "# In practice, replace with your actual data loading\n",
    "\n",
    "# Create sample data for demonstration\n",
    "sample_data = pd.DataFrame({\n",
    "    'protein_pdb_path': ['data/structures/protein_001.pdb'] * 100,\n",
    "    'ligand_sdf_path': ['data/structures/ligand_001.sdf'] * 100,\n",
    "    'smiles': ['CC(C)CC1=CC=C(C=C1)C(C)C(O)=O'] * 100,\n",
    "    'pKi': np.random.normal(7.0, 1.5, 100),\n",
    "    'pEC50': np.random.normal(6.5, 1.2, 100),\n",
    "    'pKd': np.random.normal(7.2, 1.3, 100),\n",
    "    'pIC50': np.random.normal(6.8, 1.4, 100)\n",
    "})\n",
    "\n",
    "# Add some missing values to simulate real data\n",
    "for col in ['pKi', 'pEC50', 'pKd', 'pIC50']:\n",
    "    mask = np.random.random(100) < 0.2\n",
    "    sample_data.loc[mask, col] = np.nan\n",
    "\n",
    "print(f\"Loaded {len(sample_data)} data points\")\n",
    "print(\"\\nData overview:\")\n",
    "print(sample_data.info())\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Data Quality Analysis\n",
    "\n",
    "# %%\n",
    "# Analyze task distributions\n",
    "task_cols = ['pKi', 'pEC50', 'pKd', 'pIC50']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, task in enumerate(task_cols):\n",
    "    ax = axes[i]\n",
    "    valid_data = sample_data[task].dropna()\n",
    "    \n",
    "    ax.hist(valid_data, bins=30, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(valid_data.mean(), color='red', linestyle='--', label=f'Mean: {valid_data.mean():.2f}')\n",
    "    ax.axvline(valid_data.median(), color='green', linestyle='--', label=f'Median: {valid_data.median():.2f}')\n",
    "    \n",
    "    ax.set_xlabel(task)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{task} Distribution (n={len(valid_data)})')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Activity Value Distributions', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nTask Statistics:\")\n",
    "print(\"=\"*50)\n",
    "for task in task_cols:\n",
    "    valid_data = sample_data[task].dropna()\n",
    "    print(f\"{task:10s}: n={len(valid_data):4d}, mean={valid_data.mean():.2f}, \"\n",
    "          f\"std={valid_data.std():.2f}, min={valid_data.min():.2f}, max={valid_data.max():.2f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Molecular Featurization Example\n",
    "\n",
    "# %%\n",
    "# Initialize featurizers\n",
    "drug_featurizer = DrugFeaturizer()\n",
    "protein_featurizer = ProteinFeaturizer()\n",
    "\n",
    "# Example: Featurize a drug from SMILES\n",
    "smiles_example = \"CC(C)CC1=CC=C(C=C1)C(C)C(O)=O\"\n",
    "print(f\"Featurizing SMILES: {smiles_example}\")\n",
    "\n",
    "drug_graph = drug_featurizer.featurize_from_smiles(smiles_example)\n",
    "if drug_graph:\n",
    "    print(f\"  Nodes: {drug_graph.x.shape[0]}\")\n",
    "    print(f\"  Node features: {drug_graph.x.shape[1]}\")\n",
    "    print(f\"  Edges: {drug_graph.edge_index.shape[1]}\")\n",
    "    print(f\"  Edge features: {drug_graph.edge_attr.shape[1] if drug_graph.edge_attr is not None else 0}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Data Splitting\n",
    "\n",
    "# %%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train/validation/test\n",
    "train_data, test_data = train_test_split(\n",
    "    sample_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data, \n",
    "    test_size=0.125,  # 0.125 * 0.8 = 0.1 of total\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"  Train: {len(train_data)} ({len(train_data)/len(sample_data)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(val_data)} ({len(val_data)/len(sample_data)*100:.1f}%)\")\n",
    "print(f\"  Test: {len(test_data)} ({len(test_data)/len(sample_data)*100:.1f}%)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Calculate Task Ranges for Multi-Task Learning\n",
    "\n",
    "# %%\n",
    "# Calculate task ranges for loss weighting\n",
    "task_ranges = {}\n",
    "for task in task_cols:\n",
    "    valid_values = train_data[task].dropna()\n",
    "    if len(valid_values) > 0:\n",
    "        task_ranges[task] = valid_values.max() - valid_values.min()\n",
    "    else:\n",
    "        task_ranges[task] = 1.0\n",
    "\n",
    "print(\"\\nTask ranges for loss weighting:\")\n",
    "print(\"=\"*50)\n",
    "for task, range_val in task_ranges.items():\n",
    "    weight = 1.0 / range_val if range_val > 0 else 1.0\n",
    "    normalized_weight = weight / sum(1.0/r if r > 0 else 1.0 for r in task_ranges.values())\n",
    "    print(f\"{task:10s}: range={range_val:.2f}, normalized_weight={normalized_weight:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Save Processed Data\n",
    "\n",
    "# %%\n",
    "# Save processed data\n",
    "output_dir = Path(config.data.processed_dir)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save splits\n",
    "train_data.to_parquet(output_dir / 'train_data.parquet', index=False)\n",
    "val_data.to_parquet(output_dir / 'val_data.parquet', index=False)\n",
    "test_data.to_parquet(output_dir / 'test_data.parquet', index=False)\n",
    "\n",
    "# Save task ranges\n",
    "import json\n",
    "with open(output_dir / 'task_ranges.json', 'w') as f:\n",
    "    json.dump(task_ranges, f, indent=2)\n",
    "\n",
    "print(f\"\\nData saved to {output_dir}\")\n",
    "print(\"Files created:\")\n",
    "for file in output_dir.glob('*.parquet'):\n",
    "    print(f\"  - {file.name}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Data Quality Checks\n",
    "\n",
    "# %%\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per task:\")\n",
    "print(\"=\"*50)\n",
    "for task in task_cols:\n",
    "    missing = train_data[task].isna().sum()\n",
    "    total = len(train_data)\n",
    "    print(f\"{task:10s}: {missing:4d} / {total:4d} ({missing/total*100:.1f}%)\")\n",
    "\n",
    "# Check correlations between tasks\n",
    "correlation_matrix = train_data[task_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Task Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Next Steps\n",
    "# \n",
    "# Now that the data is prepared, you can:\n",
    "# 1. Move to `02_model_training.ipynb` to train the model\n",
    "# 2. Customize the featurization process for your specific molecules\n",
    "# 3. Add additional data preprocessing steps as needed\n",
    "# \n",
    "# The prepared data includes:\n",
    "# - Standardized molecular structures\n",
    "# - Computed molecular properties\n",
    "# - Task value distributions\n",
    "# - Train/validation/test splits\n",
    "# - Task ranges for multi-task learning"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-chemprop_MTL-chemprop_mtl",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "chemprop_MTL",
   "language": "python",
   "name": "conda-env-chemprop_MTL-chemprop_mtl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
